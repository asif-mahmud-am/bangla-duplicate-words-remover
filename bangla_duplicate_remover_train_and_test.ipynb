{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asif/anaconda3/envs/bekoron/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, BertTokenizer, get_scheduler\n",
    "from datasets import load_from_disk\n",
    "from torch.optim import AdamW\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sagorsarker/bangla-bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data For Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"/home/asif/bekoron/duplicate-remover/duplicate_tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1248821\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 138656\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/asif/bekoron/duplicate-remover/duplicate_tokenized_dataset/train/cache-413b9c71c548b620.arrow\n",
      "Loading cached shuffled indices for dataset at /home/asif/bekoron/duplicate-remover/duplicate_tokenized_dataset/validation/cache-2aade1dc291a792e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1248821))\n",
    "eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(138656))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader) \n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 39026/195130 [3:24:27<13:18:42,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, validation accuracy: 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 78052/195130 [6:57:21<10:00:51,  3.25it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, validation accuracy: 0.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 117078/195130 [10:31:02<6:31:39,  3.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, validation accuracy: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 156104/195130 [14:04:17<3:22:05,  3.22it/s]    "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "patience_counter = 0\n",
    "early_stopping_patience = 3\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in eval_dataloader:\n",
    "            val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "            val_outputs = model(**val_batch)\n",
    "            val_logits = val_outputs.logits\n",
    "            val_predictions = torch.argmax(val_logits, dim=1)\n",
    "            val_labels = val_batch['labels']\n",
    "            val_accuracy += torch.sum(val_predictions == val_labels).item()\n",
    "\n",
    "    val_accuracy /= len(eval_dataset)\n",
    "    print(f\"Epoch {epoch}, validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save model if validation accuracy improves\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        torch.save(model.state_dict(), 'duplicate_remover.pt')\n",
    "        best_val_accuracy = val_accuracy\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Early stopping callback\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"No improvement in validation accuracy for {early_stopping_patience} epochs. Training stopped.\")\n",
    "        break\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sagorsarker/bangla-bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/asif/bekoron/duplicate-remover/duplicate_remover.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace TEXT_TO_CLASSIFY with the text you want to classify\n",
    "text = \"আমার খুব ভয় করে করে ওখানে যেতে\"\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# convert the tokens to IDs\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# create a PyTorch tensor from the IDs\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "# optional: if your model uses GPU, move the tensor to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    tokens_tensor = tokens_tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# get the model's prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "\n",
    "# convert the output to probabilities\n",
    "probs = nn.functional.softmax(outputs[0], dim=-1)\n",
    "\n",
    "# get the predicted class (the class with the highest probability)\n",
    "predicted_class = torch.argmax(probs).item()\n",
    "\n",
    "# print the predicted class\n",
    "print(predicted_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_from_disk(\"/home/asif/bekoron/duplicate-remover/duplicate_tokenized_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 70000\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [01:04<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " testing accuracy: 0.9518\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(len(test_dataloader)))\n",
    "model.eval()\n",
    "test_accuracy = 0.0\n",
    "with torch.no_grad():\n",
    "    for val_batch in test_dataloader:\n",
    "        val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "        val_outputs = model(**val_batch)\n",
    "        val_logits = val_outputs.logits\n",
    "        val_predictions = torch.argmax(val_logits, dim=1)\n",
    "        val_labels = val_batch['labels']\n",
    "        test_accuracy += torch.sum(val_predictions == val_labels).item()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "test_accuracy /= len(test_dataset)\n",
    "print(f\" testing accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [13:40<00:00,  9.42it/s]  "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_batch in test_dataloader:\n",
    "        val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "        val_outputs = model(**val_batch)\n",
    "        val_logits = val_outputs.logits\n",
    "        val_predictions = torch.argmax(val_logits, dim=1)\n",
    "        predicted_labels += val_predictions.cpu().numpy().tolist()\n",
    "        true_labels += val_batch[\"labels\"].cpu().numpy().tolist()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     35000\n",
      "           1       0.95      0.95      0.95     35000\n",
      "\n",
      "    accuracy                           0.95     70000\n",
      "   macro avg       0.95      0.95      0.95     70000\n",
      "weighted avg       0.95      0.95      0.95     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33432  1568]\n",
      " [ 1806 33194]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion_matrix = np.array([[33432, 1568], [1806, 33194]])\n",
    "sns.heatmap(confusion_matrix, cmap=\"Blues\", annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar-checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "62d1fca435921dec9fc954b0980014abe40ba186103ca47b4b1461d794704458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
